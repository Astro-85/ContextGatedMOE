{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93edba44-7a35-4492-a5ce-0ef21dfb13c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "import evaluate\n",
    "import transformers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import T5ForConditionalGeneration, T5TokenizerFast\n",
    "\n",
    "import loralib as lora\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca3f5c0a-195e-4626-80f0-b02d7ce268fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QA_Dataset(Dataset):\n",
    "    '''\n",
    "    Follow the question answering input format of UnifiedQA: https://arxiv.org/pdf/2005.00700.pdf\n",
    "    '''\n",
    "    def __init__(self, tokenizer, dataframe, q_len, t_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.q_len = q_len\n",
    "        self.t_len = t_len\n",
    "        self.data = dataframe\n",
    "        self.question = self.data['question']\n",
    "        self.choices = self.data['choices']\n",
    "        self.label = self.data['label']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.question)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        question = self.question[idx]\n",
    "        choices = self.choices[idx]\n",
    "        label = int(self.label[idx])\n",
    "        answer = choices[label]\n",
    "        \n",
    "        # Append choices to question following style of UnifiedQA\n",
    "        # question \\n (A) c1 (B) c2 . . .       \n",
    "        letters = ['(A)', '(B)', '(C)', '(D)', '(E)']\n",
    "        question = question + ' \\n'\n",
    "        for i, c in enumerate(choices):\n",
    "            question += f' {letters[i]} {c}'\n",
    "        question_for_tok =  question\n",
    "        answer_for_tok = answer\n",
    "        question_tokenized = self.tokenizer(question_for_tok, max_length=self.q_len, padding=\"max_length\",\n",
    "                                            truncation=True, pad_to_max_length=True, add_special_tokens=True)\n",
    "        answer_tokenized = self.tokenizer(answer_for_tok, max_length=self.t_len, padding=\"max_length\", \n",
    "                                          truncation=True, pad_to_max_length=True, add_special_tokens=True)\n",
    "    \n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(question_tokenized[\"input_ids\"], dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(question_tokenized[\"attention_mask\"], dtype=torch.long),\n",
    "            \"decoder_input_ids\": torch.tensor(answer_tokenized[\"input_ids\"], dtype=torch.long),\n",
    "            \"decoder_attention_mask\": torch.tensor(answer_tokenized[\"attention_mask\"], dtype=torch.long),\n",
    "            \"question\": question,\n",
    "            \"ref_answer\": answer,\n",
    "        }\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, tokenizer, \n",
    "                 train_loader1, val_loader1, \n",
    "                 train_loader2, val_loader2, \n",
    "                 train_loader3, val_loader3, \n",
    "                 device='cuda'):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.tokenizer = tokenizer\n",
    "        self.train_loader1 = train_loader1\n",
    "        self.val_loader1 = val_loader1\n",
    "        self.train_loader2 = train_loader2\n",
    "        self.val_loader2 = val_loader2\n",
    "        self.train_loader3 = train_loader3\n",
    "        self.val_loader3 = val_loader3\n",
    "        self.device = device\n",
    "        self.bleu = evaluate.load(\"google_bleu\")\n",
    "\n",
    "        assert len(train_loader1) == len(train_loader2)\n",
    "        assert len(train_loader2) == len(train_loader3)\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.train()\n",
    "\n",
    "        train_loss = 0\n",
    "        train_batch_count = 0\n",
    "        for multi_data_batch in tqdm_notebook(zip(self.train_loader1, self.train_loader2, self.train_loader3), \n",
    "                                              desc=\"Training batches\", total=len(self.train_loader1)):\n",
    "            for batch in multi_data_batch:\n",
    "                input_ids = batch[\"input_ids\"].to(self.device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "                labels = batch[\"decoder_input_ids\"].to(self.device)\n",
    "                decoder_attention_mask = batch[\"decoder_attention_mask\"].to(self.device)\n",
    "        \n",
    "                outputs = self.model(input_ids=input_ids,\n",
    "                                     attention_mask=attention_mask,\n",
    "                                     labels=labels,\n",
    "                                     decoder_attention_mask=decoder_attention_mask)\n",
    "        \n",
    "                self.optimizer.zero_grad()\n",
    "                outputs.loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_loss += outputs.loss.item()\n",
    "                train_batch_count += 1\n",
    "\n",
    "        return train_loss / train_batch_count\n",
    "\n",
    "    def validate_epoch(self, dataset_num):\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        val_loss = 0\n",
    "        val_batch_count = 0\n",
    "        predicted_answers = []\n",
    "        ref_answers = []\n",
    "        correct_num = 0\n",
    "        total_num = 0\n",
    "\n",
    "        if dataset_num == 1:\n",
    "            val_loader = self.val_loader1\n",
    "        elif dataset_num == 2:\n",
    "            val_loader = self.val_loader2\n",
    "        elif dataset_num == 3:\n",
    "            val_loader = self.val_loader3\n",
    "        \n",
    "        for batch in tqdm_notebook(val_loader, desc=\"Validation batches\"):\n",
    "            input_ids = batch[\"input_ids\"].to(self.device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "            labels = batch[\"decoder_input_ids\"].to(self.device)\n",
    "            decoder_attention_mask = batch[\"decoder_attention_mask\"].to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(input_ids=input_ids,\n",
    "                                     attention_mask=attention_mask,\n",
    "                                     labels=labels,\n",
    "                                     decoder_attention_mask=decoder_attention_mask)\n",
    "                val_loss += outputs.loss.item()\n",
    "                val_batch_count += 1\n",
    "    \n",
    "            # Store val outputs and metrics\n",
    "            bs = outputs.logits.shape[0]\n",
    "            for b_idx in range(bs):\n",
    "                logits = outputs.logits[b_idx]\n",
    "                tokens = torch.argmax(logits, dim=1)\n",
    "                end_tok_idx = (tokens == 1).nonzero()\n",
    "    \n",
    "                if end_tok_idx.size(0) > 0:\n",
    "                    end_tok_idx = end_tok_idx[0].item()\n",
    "                    if end_tok_idx+1 < tokens.size(0):\n",
    "                        tokens[end_tok_idx+1:] = 0\n",
    "                \n",
    "                predicted_answer = self.tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "                ref_answer = batch['ref_answer'][b_idx]\n",
    "    \n",
    "                predicted_answers.append(predicted_answer)\n",
    "                ref_answers.append(ref_answer)\n",
    "                if ref_answer in predicted_answer:\n",
    "                    correct_num += 1\n",
    "                total_num += 1\n",
    "        \n",
    "        # Finish calculating val metrics\n",
    "        val_acc = correct_num / total_num\n",
    "        bleu_score = self.bleu.compute(predictions=predicted_answers, references=ref_answers)['google_bleu']\n",
    "\n",
    "        return {'val_loss': val_loss/val_batch_count, 'val_acc': val_acc, 'bleu_score': bleu_score}\n",
    "\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_acc = -float('inf')\n",
    "\n",
    "    def early_stop(self, validation_acc):\n",
    "        if validation_acc > self.min_validation_acc + self.min_delta:\n",
    "            self.min_validation_acc = validation_acc\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "def apply_lora(model, num_blocks=12, model_d=768, lora_r=16):\n",
    "    # Apply LoRA to all attention matrices in the transformer block: q,k,v,o\n",
    "    for i in range(num_blocks):\n",
    "        model.encoder.block[i].layer[0].SelfAttention.q = lora.DWMLinear(model_d, model_d, r=lora_r, bias=False)\n",
    "        model.encoder.block[i].layer[0].SelfAttention.k = lora.Linear(model_d, model_d, r=lora_r, bias=False)\n",
    "        model.encoder.block[i].layer[0].SelfAttention.v = lora.Linear(model_d, model_d, r=lora_r, bias=False)\n",
    "        model.encoder.block[i].layer[0].SelfAttention.o = lora.Linear(model_d, model_d, r=lora_r, bias=False)\n",
    "        \n",
    "        model.decoder.block[i].layer[0].SelfAttention.q = lora.Linear(model_d, model_d, r=lora_r, bias=False)\n",
    "        model.decoder.block[i].layer[0].SelfAttention.k = lora.Linear(model_d, model_d, r=lora_r, bias=False)\n",
    "        model.decoder.block[i].layer[0].SelfAttention.v = lora.Linear(model_d, model_d, r=lora_r, bias=False)\n",
    "        model.decoder.block[i].layer[0].SelfAttention.o = lora.Linear(model_d, model_d, r=lora_r, bias=False)\n",
    "        \n",
    "        model.decoder.block[i].layer[1].EncDecAttention.q = lora.Linear(model_d, model_d, r=lora_r, bias=False)\n",
    "        model.decoder.block[i].layer[1].EncDecAttention.k = lora.Linear(model_d, model_d, r=lora_r, bias=False)\n",
    "        model.decoder.block[i].layer[1].EncDecAttention.v = lora.Linear(model_d, model_d, r=lora_r, bias=False)\n",
    "        model.decoder.block[i].layer[1].EncDecAttention.o = lora.Linear(model_d, model_d, r=lora_r, bias=False)\n",
    "\n",
    "def apply_lora_dwm(model,\n",
    "                   commonsense_lora_weights,\n",
    "                   medical_lora_weights,\n",
    "                   science_lora_weights,\n",
    "                   num_blocks=12):\n",
    "    # Apply LoRA to all attention matrices in the transformer block: q,k,v,o\n",
    "    for i in range(num_blocks):\n",
    "        \n",
    "        lora_A_weights = [commonsense_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.q.lora_A'],\n",
    "                          medical_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.q.lora_A'],\n",
    "                          science_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.q.lora_A']]\n",
    "        lora_B_weights = [commonsense_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.q.lora_B'],\n",
    "                          medical_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.q.lora_B'],\n",
    "                          science_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.q.lora_B']]\n",
    "        model.encoder.block[i].layer[0].SelfAttention.q = lora.DWMLinear(lora_A_weights, lora_B_weights, bias=False)\n",
    "\n",
    "        lora_A_weights = [commonsense_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.k.lora_A'],\n",
    "                          medical_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.k.lora_A'],\n",
    "                          science_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.k.lora_A']]\n",
    "        lora_B_weights = [commonsense_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.k.lora_B'],\n",
    "                          medical_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.k.lora_B'],\n",
    "                          science_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.k.lora_B']]\n",
    "        model.encoder.block[i].layer[0].SelfAttention.k = lora.DWMLinear(lora_A_weights, lora_B_weights, bias=False)\n",
    "\n",
    "        lora_A_weights = [commonsense_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.v.lora_A'],\n",
    "                          medical_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.v.lora_A'],\n",
    "                          science_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.v.lora_A']]\n",
    "        lora_B_weights = [commonsense_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.v.lora_B'],\n",
    "                          medical_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.v.lora_B'],\n",
    "                          science_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.v.lora_B']]\n",
    "        model.encoder.block[i].layer[0].SelfAttention.v = lora.DWMLinear(lora_A_weights, lora_B_weights, bias=False)\n",
    "\n",
    "        lora_A_weights = [commonsense_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.o.lora_A'],\n",
    "                          medical_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.o.lora_A'],\n",
    "                          science_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.o.lora_A']]\n",
    "        lora_B_weights = [commonsense_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.o.lora_B'],\n",
    "                          medical_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.o.lora_B'],\n",
    "                          science_lora_weights[f'encoder.block.{i}.layer.0.SelfAttention.o.lora_B']]\n",
    "        model.encoder.block[i].layer[0].SelfAttention.o = lora.DWMLinear(lora_A_weights, lora_B_weights, bias=False)\n",
    "\n",
    "        lora_A_weights = [commonsense_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.q.lora_A'],\n",
    "                          medical_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.q.lora_A'],\n",
    "                          science_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.q.lora_A']]\n",
    "        lora_B_weights = [commonsense_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.q.lora_B'],\n",
    "                          medical_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.q.lora_B'],\n",
    "                          science_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.q.lora_B']]\n",
    "        model.decoder.block[i].layer[0].SelfAttention.q = lora.DWMLinear(lora_A_weights, lora_B_weights, bias=False)\n",
    "\n",
    "        lora_A_weights = [commonsense_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.k.lora_A'],\n",
    "                          medical_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.k.lora_A'],\n",
    "                          science_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.k.lora_A']]\n",
    "        lora_B_weights = [commonsense_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.k.lora_B'],\n",
    "                          medical_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.k.lora_B'],\n",
    "                          science_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.k.lora_B']]\n",
    "        model.decoder.block[i].layer[0].SelfAttention.k = lora.DWMLinear(lora_A_weights, lora_B_weights, bias=False)\n",
    "\n",
    "        lora_A_weights = [commonsense_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.v.lora_A'],\n",
    "                          medical_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.v.lora_A'],\n",
    "                          science_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.v.lora_A']]\n",
    "        lora_B_weights = [commonsense_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.v.lora_B'],\n",
    "                          medical_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.v.lora_B'],\n",
    "                          science_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.v.lora_B']]\n",
    "        model.decoder.block[i].layer[0].SelfAttention.v = lora.DWMLinear(lora_A_weights, lora_B_weights, bias=False)\n",
    "\n",
    "        lora_A_weights = [commonsense_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.o.lora_A'],\n",
    "                          medical_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.o.lora_A'],\n",
    "                          science_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.o.lora_A']]\n",
    "        lora_B_weights = [commonsense_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.o.lora_B'],\n",
    "                          medical_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.o.lora_B'],\n",
    "                          science_lora_weights[f'decoder.block.{i}.layer.0.SelfAttention.o.lora_B']]\n",
    "        model.decoder.block[i].layer[0].SelfAttention.o = lora.DWMLinear(lora_A_weights, lora_B_weights, bias=False)\n",
    "\n",
    "        lora_A_weights = [commonsense_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.q.lora_A'],\n",
    "                          medical_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.q.lora_A'],\n",
    "                          science_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.q.lora_A']]\n",
    "        lora_B_weights = [commonsense_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.q.lora_B'],\n",
    "                          medical_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.q.lora_B'],\n",
    "                          science_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.q.lora_B']]\n",
    "        model.decoder.block[i].layer[1].EncDecAttention.q = lora.DWMLinear(lora_A_weights, lora_B_weights, bias=False)\n",
    "\n",
    "        lora_A_weights = [commonsense_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.k.lora_A'],\n",
    "                          medical_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.k.lora_A'],\n",
    "                          science_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.k.lora_A']]\n",
    "        lora_B_weights = [commonsense_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.k.lora_B'],\n",
    "                          medical_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.k.lora_B'],\n",
    "                          science_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.k.lora_B']]\n",
    "        model.decoder.block[i].layer[1].EncDecAttention.k = lora.DWMLinear(lora_A_weights, lora_B_weights, bias=False)\n",
    "\n",
    "        lora_A_weights = [commonsense_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.v.lora_A'],\n",
    "                          medical_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.v.lora_A'],\n",
    "                          science_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.v.lora_A']]\n",
    "        lora_B_weights = [commonsense_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.v.lora_B'],\n",
    "                          medical_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.v.lora_B'],\n",
    "                          science_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.v.lora_B']]\n",
    "        model.decoder.block[i].layer[1].EncDecAttention.v = lora.DWMLinear(lora_A_weights, lora_B_weights, bias=False)\n",
    "\n",
    "        lora_A_weights = [commonsense_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.o.lora_A'],\n",
    "                          medical_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.o.lora_A'],\n",
    "                          science_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.o.lora_A']]\n",
    "        lora_B_weights = [commonsense_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.o.lora_B'],\n",
    "                          medical_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.o.lora_B'],\n",
    "                          science_lora_weights[f'decoder.block.{i}.layer.1.EncDecAttention.o.lora_B']]\n",
    "        model.decoder.block[i].layer[1].EncDecAttention.o = lora.DWMLinear(lora_A_weights, lora_B_weights, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf0baca2-a5f3-4f27-94a9-4279beabea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base model\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base', return_dict=True)\n",
    "\n",
    "# Load finetuned LoRA weights\n",
    "commonsense_lora_weights = torch.load('results/commonsense_qa/t5_base_lora_best.pth')\n",
    "medical_lora_weights = torch.load('results/medical_qa/t5_base_lora_best.pth')\n",
    "science_lora_weights = torch.load('results/science_qa/t5_base_lora_best.pth')\n",
    "\n",
    "# Apply lora dwm and reload base model weights\n",
    "apply_lora_dwm(model, commonsense_lora_weights, medical_lora_weights, science_lora_weights)\n",
    "model.load_state_dict(torch.load('t5-base.pth'), strict=False)\n",
    "\n",
    "# Set only mixing module weights to require grad\n",
    "for n, p in model.named_parameters():\n",
    "    if 'context_gated_mixing' in n:\n",
    "        p.requires_grad = True\n",
    "    else:\n",
    "        p.requires_grad = False\n",
    "\n",
    "tokenizer = T5TokenizerFast.from_pretrained('t5-base')\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-3, eps=1e-8, weight_decay=0.0) # For lora, use 3e-3, otherwise 1e-4 learning rate\n",
    "q_len = 512   # Question Length\n",
    "t_len = 64    # Target Length\n",
    "train_batch_size = 16\n",
    "val_batch_size = 8\n",
    "device = 'cuda:0'\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b67cb7-5cc8-4c98-ae10-e54e119fd7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "commonsense_train_file = 'datasets/CommonsenseQA/commonsenseqa_mcq_train.json'\n",
    "commonsense_val_file = 'datasets/CommonsenseQA/commonsenseqa_mcq_val.json'\n",
    "medical_train_file = 'datasets/MedQA/medqa_mcq_train.json'\n",
    "medical_val_file = 'datasets/MedQA/medqa_mcq_val.json'\n",
    "science_train_file = 'datasets/ScienceQA/scienceqa_mcq_train.json'\n",
    "science_val_file = 'datasets/ScienceQA/scienceqa_mcq_val.json'\n",
    "\n",
    "with open(commonsense_train_file) as file:\n",
    "    commonsense_train_data = json.load(file)\n",
    "    \n",
    "with open(commonsense_val_file) as file:\n",
    "    commonsense_val_data = json.load(file)\n",
    "\n",
    "with open(medical_train_file) as file:\n",
    "    medical_train_data = json.load(file)\n",
    "    \n",
    "with open(medical_val_file) as file:\n",
    "    medical_val_data = json.load(file)\n",
    "\n",
    "with open(science_train_file) as file:\n",
    "    science_train_data = json.load(file)\n",
    "    \n",
    "with open(science_val_file) as file:\n",
    "    science_val_data = json.load(file)\n",
    "\n",
    "# Create Dataframes\n",
    "commonsense_train_data = pd.DataFrame(commonsense_train_data)[:256]\n",
    "commonsense_val_data = pd.DataFrame(commonsense_val_data)\n",
    "medical_train_data = pd.DataFrame(medical_train_data)[:256]\n",
    "medical_val_data = pd.DataFrame(medical_val_data)\n",
    "science_train_data = pd.DataFrame(science_train_data)[:256]\n",
    "science_val_data = pd.DataFrame(science_val_data)\n",
    "\n",
    "# Dataset\n",
    "commonsense_train_dataset = QA_Dataset(tokenizer, commonsense_train_data, q_len, t_len)\n",
    "commonsense_val_dataset = QA_Dataset(tokenizer, commonsense_val_data, q_len, t_len)\n",
    "medical_train_dataset = QA_Dataset(tokenizer, medical_train_data, q_len, t_len)\n",
    "medical_val_dataset = QA_Dataset(tokenizer, medical_val_data, q_len, t_len)\n",
    "science_train_dataset = QA_Dataset(tokenizer, science_train_data, q_len, t_len)\n",
    "science_val_dataset = QA_Dataset(tokenizer, science_val_data, q_len, t_len)\n",
    "\n",
    "# We might need less to data to train the mixing module since it has few parameters and is contrained\n",
    "#num_samples = 5000\n",
    "#commonsense_train_random_sampler = RandomSampler(commonsense_train_dataset, num_samples=num_samples)\n",
    "#medical_train_random_sampler = RandomSampler(medical_train_dataset, num_samples=num_samples)\n",
    "#science_train_random_sampler = RandomSampler(science_train_dataset, num_samples=num_samples)\n",
    "\n",
    "# Dataloader\n",
    "commonsense_train_loader = DataLoader(commonsense_train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "commonsense_val_loader = DataLoader(commonsense_val_dataset, batch_size=val_batch_size, shuffle=False)\n",
    "\n",
    "medical_train_loader = DataLoader(medical_train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "medical_val_loader = DataLoader(medical_val_dataset, batch_size=val_batch_size, shuffle=False)\n",
    "\n",
    "science_train_loader = DataLoader(science_train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "science_val_loader = DataLoader(science_val_dataset, batch_size=val_batch_size, shuffle=False)\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(model, optimizer, tokenizer, \n",
    "                  commonsense_train_loader, commonsense_val_loader,\n",
    "                  medical_train_loader, medical_val_loader,\n",
    "                  science_train_loader, science_val_loader,\n",
    "                  device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3c35281-93d1-4274-8f84-d0f6c4e74047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efeb2358834f475aac172d699ac2bc1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4726404c0cd4bb08e45ea15b1989268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c94785cdd542eb912a3e2a226ea55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/50 -> Validation Acc: 0.563 \tValidation Bleu: 0.665\n",
      "0/50 -> Validation Acc: 0.256 \tValidation Bleu: 0.750\n",
      "0/50 -> Validation Acc: 0.759 \tValidation Bleu: 0.962\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94da00e3e76a444d9a8aeadc7eb9caf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94eefa9ea64409294c719acdc3769f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05dfa9cbd2046949a9a7cbd3ed0552d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02573fc172f842f7a5792bce361cd054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/50 -> Validation Acc: 0.568 \tValidation Bleu: 0.671\n",
      "31/50 -> Validation Acc: 0.252 \tValidation Bleu: 0.750\n",
      "31/50 -> Validation Acc: 0.764 \tValidation Bleu: 0.964\n",
      "Saving model...\n",
      "31/50 -> Train loss: 0.019526762980228617 \tValidation loss: 0.02366111822936277 \tValidation Acc: 0.528 \tValidation Bleu: 0.795\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54a8a7f38534fdeae088d0dccf10f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7623fa93204f2c8259c47e4f000f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d5464ffd6e424ca4f67a1a327e3edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea456d5a3f14440385b4f6e3d940cb49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/50 -> Validation Acc: 0.572 \tValidation Bleu: 0.673\n",
      "32/50 -> Validation Acc: 0.263 \tValidation Bleu: 0.755\n",
      "32/50 -> Validation Acc: 0.765 \tValidation Bleu: 0.964\n",
      "Saving model...\n",
      "32/50 -> Train loss: 0.019291037138029144 \tValidation loss: 0.023641108133271097 \tValidation Acc: 0.533 \tValidation Bleu: 0.798\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8950e04228b1400c9cb366b2395b793f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e072803dd8d7453387dc03c72570e0b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55499d94635b42ea996d5fbb28505c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9072064bce411bbd4eab413a5c55c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/50 -> Validation Acc: 0.594 \tValidation Bleu: 0.684\n",
      "33/50 -> Validation Acc: 0.253 \tValidation Bleu: 0.750\n",
      "33/50 -> Validation Acc: 0.765 \tValidation Bleu: 0.963\n",
      "Saving model...\n",
      "33/50 -> Train loss: 0.018911667080058977 \tValidation loss: 0.023624894275452935 \tValidation Acc: 0.537 \tValidation Bleu: 0.799\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d2bc55670b4212beb83e3adb1dc0ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec2e2754ff64eccbb8dd16c08de15c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97697c2704f14c9194ff370e64c86a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55e0c6db57b4b9e97a2f4fa64eb5a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/50 -> Validation Acc: 0.599 \tValidation Bleu: 0.692\n",
      "34/50 -> Validation Acc: 0.252 \tValidation Bleu: 0.749\n",
      "34/50 -> Validation Acc: 0.758 \tValidation Bleu: 0.962\n",
      "Saving model...\n",
      "34/50 -> Train loss: 0.01905149064967951 \tValidation loss: 0.023714500132720667 \tValidation Acc: 0.536 \tValidation Bleu: 0.801\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925981e5a2f24af08e8f87920292225b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd524b44d2314a7e9048b6b12e8256ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe842484ebf4725984b2e1fb2d1664f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe928c26b2484c92b9946317f8f80db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/50 -> Validation Acc: 0.603 \tValidation Bleu: 0.690\n",
      "35/50 -> Validation Acc: 0.248 \tValidation Bleu: 0.752\n",
      "35/50 -> Validation Acc: 0.768 \tValidation Bleu: 0.964\n",
      "Saving model...\n",
      "35/50 -> Train loss: 0.018294959591465102 \tValidation loss: 0.023536785844628694 \tValidation Acc: 0.540 \tValidation Bleu: 0.802\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800915f5955a4c7986540e515d1b8d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d524255a3438419ba65c97cc7b1bee27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9b2166e0ac405bacef8efd2a750a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0ef480dca74620a986712874e779d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/50 -> Validation Acc: 0.605 \tValidation Bleu: 0.694\n",
      "36/50 -> Validation Acc: 0.252 \tValidation Bleu: 0.748\n",
      "36/50 -> Validation Acc: 0.766 \tValidation Bleu: 0.964\n",
      "Saving model...\n",
      "36/50 -> Train loss: 0.01815860916456336 \tValidation loss: 0.023707802931973446 \tValidation Acc: 0.541 \tValidation Bleu: 0.802\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5d24bbe90e4bd9baea6edec501efcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c3aa7a5aff404ab08facf0159ad454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1074510e2614c41a08d2e01f36ae093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015f8510a0a843c6b0d3d941f0eb0cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/50 -> Validation Acc: 0.591 \tValidation Bleu: 0.687\n",
      "37/50 -> Validation Acc: 0.252 \tValidation Bleu: 0.748\n",
      "37/50 -> Validation Acc: 0.760 \tValidation Bleu: 0.963\n",
      "Saving model...\n",
      "37/50 -> Train loss: 0.01879356735725961 \tValidation loss: 0.024028197359949932 \tValidation Acc: 0.534 \tValidation Bleu: 0.799\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d25664bd12640d1b942ece7bf58ec8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f796dd213ece4364bf6f35d8acfa8705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1793db06626e41ffa1751a664e1c20cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe6363680a34225971445e28fce27e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/50 -> Validation Acc: 0.603 \tValidation Bleu: 0.693\n",
      "38/50 -> Validation Acc: 0.257 \tValidation Bleu: 0.750\n",
      "38/50 -> Validation Acc: 0.762 \tValidation Bleu: 0.963\n",
      "Saving model...\n",
      "38/50 -> Train loss: 0.0184939381834021 \tValidation loss: 0.02400259809626531 \tValidation Acc: 0.541 \tValidation Bleu: 0.802\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a11598217644bd3b06aa935c4cc491f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076f7c41dabd458e849e8611cee15d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6fd58efbe544849aace3efe32e7098d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704ab42c6f01454d8739363cd17b6d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/50 -> Validation Acc: 0.605 \tValidation Bleu: 0.698\n",
      "39/50 -> Validation Acc: 0.252 \tValidation Bleu: 0.747\n",
      "39/50 -> Validation Acc: 0.765 \tValidation Bleu: 0.963\n",
      "Saving model...\n",
      "39/50 -> Train loss: 0.01774772572966795 \tValidation loss: 0.023916958297532556 \tValidation Acc: 0.541 \tValidation Bleu: 0.803\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7569f02c9c49579b580062f204c4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672be7242bdf43108915be4c9b7c14ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b719c1f9acad4e2da111d2b85abe9d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa62d5425984442d988b3a4ed9364e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/50 -> Validation Acc: 0.607 \tValidation Bleu: 0.700\n",
      "40/50 -> Validation Acc: 0.251 \tValidation Bleu: 0.748\n",
      "40/50 -> Validation Acc: 0.769 \tValidation Bleu: 0.964\n",
      "Saving model...\n",
      "40/50 -> Train loss: 0.017105262522048578 \tValidation loss: 0.023837262424149904 \tValidation Acc: 0.542 \tValidation Bleu: 0.804\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1169e378044ffd8dfdd304b91396e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7705785802541e3a656d27d0b6b08f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c306092b9b443edb389937e79f750ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c233012279446990c9ef728547be40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/50 -> Validation Acc: 0.608 \tValidation Bleu: 0.698\n",
      "41/50 -> Validation Acc: 0.254 \tValidation Bleu: 0.748\n",
      "41/50 -> Validation Acc: 0.768 \tValidation Bleu: 0.964\n",
      "Saving model...\n",
      "41/50 -> Train loss: 0.017748134204546216 \tValidation loss: 0.02394681342351353 \tValidation Acc: 0.543 \tValidation Bleu: 0.803\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff56f5ce6f941d983dadd2cc761eb2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5672f163cbe545d7aba1a532c1efcb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dae85e5dcd84784ac067bcf41370176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51a8475354f48c0a628d6cb6aeaf958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/50 -> Validation Acc: 0.607 \tValidation Bleu: 0.697\n",
      "42/50 -> Validation Acc: 0.254 \tValidation Bleu: 0.749\n",
      "42/50 -> Validation Acc: 0.765 \tValidation Bleu: 0.964\n",
      "Saving model...\n",
      "42/50 -> Train loss: 0.01738707736817006 \tValidation loss: 0.023771098385894123 \tValidation Acc: 0.542 \tValidation Bleu: 0.803\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d41c0e854f4e04b6a51f21a9bfd33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c280e1cee9af45fe8f936ffab78ea418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f332ffc27b84aef82d8139b8adb1709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812aed9da7ee485c8b01e14ae1ce0909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/50 -> Validation Acc: 0.609 \tValidation Bleu: 0.698\n",
      "43/50 -> Validation Acc: 0.245 \tValidation Bleu: 0.747\n",
      "43/50 -> Validation Acc: 0.768 \tValidation Bleu: 0.963\n",
      "Saving model...\n",
      "43/50 -> Train loss: 0.017740434323925348 \tValidation loss: 0.02363793908106056 \tValidation Acc: 0.541 \tValidation Bleu: 0.803\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a1074994ae428e9adcc3f30359b087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109e3f03215a4c319a3732befdf8f055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f260d741a04445ecabf4e88ab24c9ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88bf2cbec8d4748a2698458cc15fae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/50 -> Validation Acc: 0.610 \tValidation Bleu: 0.699\n",
      "44/50 -> Validation Acc: 0.252 \tValidation Bleu: 0.746\n",
      "44/50 -> Validation Acc: 0.773 \tValidation Bleu: 0.965\n",
      "Saving model...\n",
      "44/50 -> Train loss: 0.01747547995013298 \tValidation loss: 0.023612347588083046 \tValidation Acc: 0.545 \tValidation Bleu: 0.803\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465d889f8c7c465fb636bbdd120ba465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fbcdc03bd79428191c660ac8e8f396d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d39a9480da64aab920c4e6e6c9b121c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1e12cbdfbf46d191ca7bb9be306d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/50 -> Validation Acc: 0.599 \tValidation Bleu: 0.691\n",
      "45/50 -> Validation Acc: 0.256 \tValidation Bleu: 0.748\n",
      "45/50 -> Validation Acc: 0.773 \tValidation Bleu: 0.964\n",
      "Saving model...\n",
      "45/50 -> Train loss: 0.017706999501642135 \tValidation loss: 0.02350466989056781 \tValidation Acc: 0.543 \tValidation Bleu: 0.801\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0437cf8e7d4effae23e7715dabbdda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e5e34b34cc4c8aae33e7b67fed2528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bca2a1966e647a2ad9c4eb9f5110d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd5f23a9528436cab21995a46f96328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/50 -> Validation Acc: 0.612 \tValidation Bleu: 0.701\n",
      "46/50 -> Validation Acc: 0.256 \tValidation Bleu: 0.750\n",
      "46/50 -> Validation Acc: 0.772 \tValidation Bleu: 0.964\n",
      "Saving model...\n",
      "46/50 -> Train loss: 0.017554981393798713 \tValidation loss: 0.023618055908393772 \tValidation Acc: 0.546 \tValidation Bleu: 0.805\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3515658d1e97442fb39718b17771e3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7b08a9ee734325b61d6a6970045326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f2b929a22a4db4b9c979afc3a9760b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35361aa7c8c47fbbdd0e2d91c564c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/50 -> Validation Acc: 0.607 \tValidation Bleu: 0.698\n",
      "47/50 -> Validation Acc: 0.247 \tValidation Bleu: 0.746\n",
      "47/50 -> Validation Acc: 0.769 \tValidation Bleu: 0.964\n",
      "Saving model...\n",
      "47/50 -> Train loss: 0.017455612112787705 \tValidation loss: 0.023664059796907635 \tValidation Acc: 0.541 \tValidation Bleu: 0.803\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03dae836ec4a415084f0d34fe4d2620c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca26a8281d1544d38c4ac38d35d7c586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530d4e684dfd400eb87e9b49904b522f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ab5bedbffd43fbb3d9637b0abd73b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/50 -> Validation Acc: 0.610 \tValidation Bleu: 0.699\n",
      "48/50 -> Validation Acc: 0.249 \tValidation Bleu: 0.748\n",
      "48/50 -> Validation Acc: 0.775 \tValidation Bleu: 0.965\n",
      "Saving model...\n",
      "48/50 -> Train loss: 0.017651351854924564 \tValidation loss: 0.023635622940292155 \tValidation Acc: 0.545 \tValidation Bleu: 0.804\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8414930c168c46bb982b3dbbd07bd1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef5cd190aa949d8a13c741f6069b29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c9aecbef8c4e51891b60e882463d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19abf80d82d4ca1a2ba170ce93526ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/50 -> Validation Acc: 0.611 \tValidation Bleu: 0.701\n",
      "49/50 -> Validation Acc: 0.252 \tValidation Bleu: 0.750\n",
      "49/50 -> Validation Acc: 0.775 \tValidation Bleu: 0.965\n",
      "Saving model...\n",
      "49/50 -> Train loss: 0.016719280923815277 \tValidation loss: 0.023731100274717313 \tValidation Acc: 0.546 \tValidation Bleu: 0.805\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e587caea83534688bd4ce027a749b6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc5dbe53901543edbf55d4ef1b1b64cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4cd2e02fdd4ac28140aa98b73ff8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4858a8cdf8224a22867e09d5132293bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation batches:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 -> Validation Acc: 0.613 \tValidation Bleu: 0.703\n",
      "50/50 -> Validation Acc: 0.252 \tValidation Bleu: 0.749\n",
      "50/50 -> Validation Acc: 0.773 \tValidation Bleu: 0.965\n",
      "Saving model...\n",
      "50/50 -> Train loss: 0.017680085942927727 \tValidation loss: 0.023577031384128606 \tValidation Acc: 0.546 \tValidation Bleu: 0.806\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "loss_log = []\n",
    "val_metrics_log = []\n",
    "best_val_acc = -1.0\n",
    "best_model_path = ''\n",
    "early_stopping = EarlyStopper(patience=5, min_delta=1e-3)\n",
    "\n",
    "# Initial validation\n",
    "val_metrics1 = trainer.validate_epoch(1)\n",
    "val_metrics2 = trainer.validate_epoch(2)\n",
    "val_metrics3 = trainer.validate_epoch(3)\n",
    "\n",
    "for val_metrics in [val_metrics1, val_metrics2, val_metrics3]:\n",
    "    val_loss = val_metrics['val_loss']\n",
    "    val_acc = val_metrics['val_acc']\n",
    "    val_bleu = val_metrics['bleu_score']\n",
    "    print(f\"{0}/{num_epochs} -> Validation Acc: {val_acc:.3f} \\tValidation Bleu: {val_bleu:.3f}\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = trainer.train_epoch()\n",
    "\n",
    "    val_metrics1 = trainer.validate_epoch(1)\n",
    "    val_metrics2 = trainer.validate_epoch(2)\n",
    "    val_metrics3 = trainer.validate_epoch(3)\n",
    "\n",
    "    avg_val_loss = 0.0\n",
    "    avg_val_acc = 0.0\n",
    "    avg_val_bleu = 0.0\n",
    "    for val_metrics in [val_metrics1, val_metrics2, val_metrics3]:\n",
    "        val_loss = val_metrics['val_loss']\n",
    "        val_acc = val_metrics['val_acc']\n",
    "        val_bleu = val_metrics['bleu_score']\n",
    "        avg_val_loss += val_loss\n",
    "        avg_val_acc += val_acc\n",
    "        avg_val_bleu += val_bleu\n",
    "        print(f\"{epoch+1}/{num_epochs} -> Validation Acc: {val_acc:.3f} \\tValidation Bleu: {val_bleu:.3f}\")\n",
    "\n",
    "    avg_val_loss /= 3\n",
    "    avg_val_acc /= 3\n",
    "    avg_val_bleu /= 3\n",
    "    \n",
    "    loss_log.append((train_loss, avg_val_loss))\n",
    "    val_metrics_log.append((avg_val_acc, avg_val_bleu))\n",
    "    \n",
    "    print('Saving model...')   \n",
    "    checkpoint_path = f'results/cgm_coarse/t5_base_lora_cgm_epoch{epoch+1}.pth'\n",
    "    torch.save(lora.cgm_state_dict(model), checkpoint_path)\n",
    "\n",
    "    if avg_val_acc > best_val_acc:\n",
    "        best_val_acc = avg_val_acc\n",
    "        best_model_path = checkpoint_path\n",
    "    \n",
    "    print(f\"{epoch+1}/{num_epochs} -> Train loss: {train_loss} \\tValidation loss: {avg_val_loss} \" + \\\n",
    "          f\"\\tValidation Acc: {avg_val_acc:.3f} \\tValidation Bleu: {avg_val_bleu:.3f}\")\n",
    "\n",
    "    if early_stopping.early_stop(avg_val_acc):\n",
    "        break\n",
    "\n",
    "torch.save(torch.load(best_model_path), 'results/cgm_coarse/t5_base_lora_cgm_best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5120b2-7612-46b3-a169-7250528feed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32054d9a-b440-4dc0-9e81-f942b891e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of additional parameters: 445104"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
